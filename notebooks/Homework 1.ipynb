{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Learning Algorithm (PLA)\n",
    "\n",
    "## Learning from Data: Homework 1\n",
    "\n",
    "### Questions 7, 8, 9, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "with open('dataset.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a random target function\n",
    "def generate_target():\n",
    "    p = np.random.uniform(-1, 1, (2,2))\n",
    "\n",
    "    x = [[z,1] for z in p[:,0]]\n",
    "    y = p[:,1]\n",
    "    a,b = np.linalg.solve(x,y)\n",
    "    \n",
    "    f = lambda x: a*x+b\n",
    "    w = [-b, -a, 1]\n",
    "    \n",
    "    Ys = np.sign(np.dot(dataset, w))\n",
    "    return (w, Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pick a random data set of the required size\n",
    "def pick_data(targets, N, dim):\n",
    "    Xs = np.zeros((N,dim))\n",
    "    Ys = np.zeros(N)\n",
    "\n",
    "    for i in range(N):\n",
    "        idx = np.random.randint(0, len(dataset))\n",
    "        Xs[i] = dataset[idx]\n",
    "        Ys[i] = targets[idx]\n",
    "    return (Xs, Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_rate(w, w_est):\n",
    "    actual_Ys = np.sign(np.dot(dataset, w))\n",
    "    predicted_Ys = np.sign(np.dot(dataset, w_est))\n",
    "\n",
    "    return np.mean(actual_Ys != predicted_Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Main PLA Algorithm\n",
    "def PLA(iterations, N, dim):\n",
    "    convergence = np.zeros(iterations)\n",
    "    error_rates = np.zeros(iterations)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        w, Y = generate_target()\n",
    "        Xs, Ys = pick_data(Y, N, dim)\n",
    "        w_est = np.zeros(dim)\n",
    "        ctr = 0\n",
    "        acc = 0\n",
    "        while acc < 1:\n",
    "            ctr += 1\n",
    "            # Make and evaluate predictions\n",
    "            pred = np.sign(np.dot(Xs, w_est))\n",
    "            wrong_Xs = Xs[pred != Ys]\n",
    "            wrong_Ys = Ys[pred != Ys]\n",
    "        \n",
    "            # Measure accuracy of current iteration\n",
    "            acc = np.mean(pred == Ys)\n",
    "        \n",
    "            # Randomly pick one misclassified point and update weight\n",
    "            if acc < 1:\n",
    "                idx = np.random.randint(len(wrong_Xs))\n",
    "                w_est = w_est + wrong_Ys[idx] * wrong_Xs[idx]        \n",
    "        convergence[i] = ctr\n",
    "        error_rates[i] = error_rate(w, w_est)\n",
    "    return (np.mean(convergence), np.mean(error_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the PLA algorithm for X iterations, with Y data points\n",
    "def main(iterations, N):\n",
    "    dim = dataset.shape[1]\n",
    "    conv, err_rate = PLA(iterations, N, dim)\n",
    "    return (conv, err_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLA run for 1000 iterations\n",
      "Dataset of size 10\n",
      "Average number of iterations needed for convergence is 10.374\n",
      "Average error rate is 0.108771\n"
     ]
    }
   ],
   "source": [
    "conv, err_rate = main(1000,10)\n",
    "print(\"PLA run for 1000 iterations\")\n",
    "print(\"Dataset of size 10\")\n",
    "print(\"Average number of iterations needed for convergence is\", conv)\n",
    "print(\"Average error rate is\", err_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLA run for 1000 iterations\n",
      "Dataset of size 100\n",
      "Average number of iterations needed for convergence is 123.62\n",
      "Average error rate is 0.01259\n"
     ]
    }
   ],
   "source": [
    "conv, err_rate = main(1000,100)\n",
    "print(\"PLA run for 1000 iterations\")\n",
    "print(\"Dataset of size 100\")\n",
    "print(\"Average number of iterations needed for convergence is\", conv)\n",
    "print(\"Average error rate is\", err_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
